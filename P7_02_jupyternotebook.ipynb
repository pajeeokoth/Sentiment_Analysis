{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', lambda x: '{:,.2f}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Sentiment Prediction\n",
    "Air Paradis has commissioned an AI product that anticipates bad buzz on social networks. The AI product can predict the sentiment associated with a tweet.\n",
    "* Data description: information about tweets (user who posted, content, time of posting) and a binary label (tweet expressing a negative sentiment or not). \n",
    "* A functional prototype of the model. That sends a tweet and retrieves the sentiment prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"kazanova/sentiment140\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the file path and read the file\n",
    "file_path = 'C:/Users/spectre/.cache/kagglehub/datasets/kazanova/sentiment140/versions/2/training.1600000.processed.noemoticon.csv'\n",
    "# read the datafile\n",
    "df = pd.read_csv(file_path, \n",
    "                sep= ',',\n",
    "                on_bad_lines='warn',\n",
    "                parse_dates=True,\n",
    "                encoding='latin-1',\n",
    "                header=None,\n",
    "                engine='python')\n",
    "# add column titles\n",
    "df.columns = ['polarity', 'id', 'date', 'query', 'user', 'text']\n",
    "# select onlt the needed columns\n",
    "df = df[['polarity', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset \n",
    "The sentiment140 dataset contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity counts: polarity\n",
      "0    800000\n",
      "4    800000\n",
      "Name: count, dtype: int64\n",
      "Target counts: target\n",
      "0    800000\n",
      "1    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. Covert polarity from 0,4 to 0,1 binary values\n",
    "df['target'] = df['polarity'].apply(lambda x: 1 if x == 4 else 0)\n",
    "# count the number of occurance for each sentiment class\n",
    "print(f'polarity counts: {df.polarity.value_counts()}\\nTarget counts: {df.target.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the text\n",
    "Convert text to lower case, remove contractions, urls, usernames, digits, punctuations stopwords, tokenize corpus and lemmatize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preprocess the text \n",
    "df = df[['target','text']]\n",
    "\n",
    "# transform corpus to lowercase\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "# Change contractions so that tokenization can work right\n",
    "import contractions\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))\n",
    "\n",
    "# Remove URLs\n",
    "df['text'] = df['text'].str.replace(r'http[s]?://\\S+|www.\\S+', '', regex=True)\n",
    "\n",
    "# Remove all @s (usernames)\n",
    "df['text'] = df['text'].str.replace(r'@\\S+', '', regex=True)\n",
    "\n",
    "# Remove hashtags\n",
    "df['text'] = df['text'].str.replace(r'#\\S+','', regex=True)\n",
    "\n",
    "# Remove digits\n",
    "df['text'] = df['text'].replace(r'\\d+', '', regex=True)\n",
    "    \n",
    "# Remove Punctuation\n",
    "df['text'] = df['text'].str.replace(r'[\\!\"#$%&\\*+,-./:;<=>?@^_`()|~=]','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Lemmatize the text\n",
    "# Lemmatize the corpus\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "# function to get a language detector\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "Language.factory(\"language_detector\", func=get_lang_detector) # load the language detector\n",
    "nlp.add_pipe('language_detector', last=True)\n",
    "\n",
    "def lemmatize(text):\n",
    "\n",
    "   doc = nlp(text)\n",
    "\n",
    "   tokens = [token.lemma_ for token in doc if not (token.is_stop or token.is_punct or token.is_digit)]\n",
    "\n",
    "   return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the  lemmatize()  function to the whole cleaned corpus with:\n",
    "df['clean_text'] = df.text.apply(lambda txt : lemmatize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Tokenize the tweets\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 5000\n",
    "tokenizer = Tokenizer(num_words=vocab_size, split=' ')\n",
    "tokenizer.fit_on_texts(df['clean_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Split data into label, features, traing and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.clean_text\n",
    "y = df.target\n",
    "# Split X and y into training and testing sets\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "# validation set\n",
    "Xvalid, yvalid = Xtrain[:64], ytrain[:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Vectorize the tweets and pad to same length\n",
    "Xtrain_ = tokenizer.texts_to_sequences(Xtrain.values)\n",
    "Xtrain_ = pad_sequences(Xtrain_)\n",
    "X_val = tokenizer.texts_to_sequences(Xvalid.values)\n",
    "X_val = pad_sequences(X_val)\n",
    "Xtest_ = tokenizer.texts_to_sequences(Xtest.values)\n",
    "Xtest_ = pad_sequences(Xtest_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1200000, 85), (64, 12), (400000, 38)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[Xtrain_.shape,X_val.shape, Xtest_.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1200000, 85), (64, 85), (400000, 85)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Xtrain_ has shape (1200000, 38), X_val has shape (64, 25), and Xtest_ has (400000, 40) need to bring to same number of tweets by filling missing with 0s\n",
    "import numpy as np\n",
    "Xtest_ = np.lib.pad(Xtest_, ((0,0),(Xtrain_.shape[1] - Xtest_.shape[1],0)), 'constant', constant_values=(0))\n",
    "X_val = np.lib.pad(X_val, ((0,0),(Xtrain_.shape[1] - X_val.shape[1],0)), 'constant', constant_values=(0))\n",
    "[Xtrain_.shape,X_val.shape,Xtest_.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training text counts: 1200000\n",
      "    Training Target counts: target\n",
      "0    600419\n",
      "1    599581\n",
      "Name: count, dtype: int64\n",
      "    --------------------------------------\n",
      "        Validating text counts: 64\n",
      "            Validating Target counts: target\n",
      "0    34\n",
      "1    30\n",
      "Name: count, dtype: int64\n",
      "                 --------------------------------------\n",
      "        Testing text counts: 400000\n",
      "            Testing Target counts: target\n",
      "1    200419\n",
      "0    199581\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Training text counts: {len(Xtrain_)}\\n\\\n",
    "    Training Target counts: {ytrain.value_counts()}\\n\\\n",
    "    --------------------------------------\\n\\\n",
    "        Validating text counts: {len(X_val)}\\n\\\n",
    "            Validating Target counts: {yvalid.value_counts()}\\n\\\n",
    "                 --------------------------------------\\n\\\n",
    "        Testing text counts: {len(Xtest_)}\\n\\\n",
    "            Testing Target counts: {ytest.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model took : 35.975924253463745 seconds \n"
     ]
    }
   ],
   "source": [
    "# 7. Train a logistic regression classifier\n",
    "start_time = time.time()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "mod_logit = LogisticRegression()\n",
    "mod_logit.fit(Xtrain_, ytrain)\n",
    "\n",
    "print(\"Training the model took : %s seconds \" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save the model\n",
    "import pickle\n",
    "import joblib \n",
    "# filename = 'logistic_model2.pkl'\n",
    "# vecname = 'vectorizer.pkl'\n",
    "\n",
    "# Save the trained model using joblib.\n",
    "# joblib.dump(mod_logit, open(filename, 'wb'))\n",
    "\n",
    "# Load the model \n",
    "# model = pickle.load(open(filename, 'rb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict and evaluate model\n",
    "def val_test(model, x_train, y_train, x_test, y_test):\n",
    "    from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "    from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, classification_report, confusion_matrix\n",
    "    # generate predictions\n",
    "    y_pred = model.predict(x_test)\n",
    "    # predicted probabilities\n",
    "    y_pred_prob = model.predict_proba(x_test)[::, 1]\n",
    "\n",
    "    # Generate a confusion matrix for the model\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_df = pd.DataFrame(\n",
    "        cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    "        )\n",
    "\n",
    "    # cross validation\n",
    "    c_v = RepeatedStratifiedKFold(n_splits=10, n_repeats= 3, random_state=13)\n",
    "    #crossvalidation score\n",
    "    crosval = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=c_v, n_jobs=-1)\n",
    "\n",
    "    # Print the classification report for the model\n",
    "    print(\"Confusion Matrix\")\n",
    "    display(cm_df)\n",
    "\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Accuracy Score : {accuracy_score(y_test, y_pred): .3f}, \\\n",
    "        Recall score: {recall_score(y_test, y_pred): .3f}\")\n",
    "    print(f'Area Under Curve: {roc_auc_score(y_test, model.predict_proba(x_test)[::,1]): .4f}, \\\n",
    "        Cross Validation Score: {crosval.mean():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>68798</td>\n",
       "      <td>130783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>64108</td>\n",
       "      <td>136311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0        68798       130783\n",
       "Actual 1        64108       136311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.34      0.41    199581\n",
      "           1       0.51      0.68      0.58    200419\n",
      "\n",
      "    accuracy                           0.51    400000\n",
      "   macro avg       0.51      0.51      0.50    400000\n",
      "weighted avg       0.51      0.51      0.50    400000\n",
      "\n",
      "Accuracy Score :  0.513,         Recall score:  0.680\n",
      "Area Under Curve:  0.5153,         Cross Validation Score: 0.513\n",
      "Validating the model took : 653.8046953678131 seconds \n"
     ]
    }
   ],
   "source": [
    "# 9. Make predictions and evaluate model\n",
    "start_time = time.time()\n",
    "val_test(mod_logit, Xtrain_, ytrain, Xtest_, ytest)\n",
    "print(\"Validating the model took : %s seconds \" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic_model (vectorized text)\n",
    "Confusion Matrix\n",
    "\n",
    "               Predicted 0\tPredicted 1\n",
    "Actual   0\t         155679\t      43902\n",
    "Actual   1\t         37085          163334\n",
    "\n",
    "Classification Report\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.81      0.78      0.79    199581\n",
    "           1       0.79      0.81      0.80    200419\n",
    "\n",
    "    accuracy                           0.80    400000\n",
    "\n",
    "   macro avg       0.80      0.80      0.80    400000\n",
    "   \n",
    "weighted avg       0.80      0.80      0.80    400000\n",
    "\n",
    "Accuracy Score :  0.798,         \n",
    "\n",
    "Recall score:  0.815\n",
    "\n",
    "Area Under Curve:  0.8698,        \n",
    "\n",
    "Cross Validation Score: 0.798\n",
    "\n",
    "### Logistic_model1 (with lemmatized text)\n",
    "Confusion Matrix\n",
    "\n",
    "               Predicted 0\tPredicted 1\n",
    "Actual 0\t      145984\t      53597\n",
    "Actual 1\t      42385\t         158034\n",
    "\n",
    "Classification Report\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.77      0.73      0.75    199581\n",
    "           1       0.75      0.79      0.77    200419\n",
    "\n",
    "    accuracy                           0.76    400000\n",
    "\n",
    "   macro avg       0.76      0.76      0.76    400000\n",
    "\n",
    "weighted avg       0.76      0.76      0.76    400000\n",
    "\n",
    "Accuracy Score :  0.760,        \n",
    "\n",
    "Recall score:  0.789\n",
    "\n",
    "Area Under Curve:  0.8360,         \n",
    "\n",
    "Cross Validation Score: 0.760\n",
    "\n",
    "Validating the model took : 346.57127499580383 seconds \n",
    "\n",
    "### Logistic_model3 (with lemmatized and padded text)\n",
    "Confusion Matrix\n",
    "\n",
    "            Predicted 0\tPredicted 1\n",
    "\n",
    "Actual 0\t   68798\t   130783\n",
    "\n",
    "Actual 1\t   64108\t   136311\n",
    "\n",
    "Classification Report\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.52      0.34      0.41    199581\n",
    "           1       0.51      0.68      0.58    200419\n",
    "\n",
    "    accuracy                           0.51    400000\n",
    "\n",
    "   macro avg       0.51      0.51      0.50    400000\n",
    "\n",
    "weighted avg       0.51      0.51      0.50    400000\n",
    "\n",
    "Accuracy Score :  0.513,         \n",
    "\n",
    "Recall score:  0.680\n",
    "\n",
    "Area Under Curve:  0.5153\n",
    "\n",
    "Cross Validation Score: 0.513\n",
    "\n",
    "Validating the model took : 653.8046953678131 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Tweet Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# 10. Supply Tweet and apply model to classify\n",
    "\n",
    "def classify_tweet(model, vectorizer, tweet):\n",
    "    tweet = str(tweet).lower().replace('#', '').replace('@', '').replace(r'http[s]?://\\S+|www.\\S+', '')\n",
    "    message_vect = vectorizer.transform([tweet])\n",
    "    prediction = model.predict(message_vect)[0]\n",
    "    return 'Positive' if prediction == 1 else 'Negative'\n",
    "\n",
    "# Example of using the function\n",
    "message = 'The food and service was this data science article is the human subject service airplane africa'\n",
    "classifier = pickle.load(open('logistic_model.pkl', 'rb')) \n",
    "vectorizer = pickle.load(open('vectorizer.pkl', 'rb'))\n",
    "print(f'Predicted Tweet Sentiment: {classify_tweet(classifier, vectorizer, message)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized Advanced Model\n",
    "## Recurrent Neural Networks\n",
    "Unlike other Neural Networks that work without memory (ie.  every single input is processed independently with no relation with the other ones.), RNN's one advantage is its ability to remember. RNN process sequences by iterating along the sequence elements and keeping information relative to what it has processed so far.\n",
    "\n",
    "There are three RNN types: a single LSTM (long short-term memory) model, a Bidirectional LSTM and the Conv1D model.\n",
    "\n",
    "Working with Neural Networks, it is important to make all the inputs in a fixed size. To achieve this objective we will pad the tweet sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gated Recurrent Units (GRU)\n",
    "Gated Recurrent Unit (GRU) is a type of recurrent neural network (RNN) that was introduced by Cho et al. in 2014 as a simpler alternative to <i><u>Long Short-Term Memory (LSTM)</u></i> networks. Like LSTM, GRU can process sequential data such as text, speech, and time-series data. GRUs are lesser known but equally robust algorithms to solve the limitations of simple RNNs.\n",
    "\n",
    "The basic idea behind GRU is to use *gating mechanisms* to selectively update the hidden state of the network at each time step. The gating mechanisms are used to control the flow of information in and out of the network. The GRU has two gating mechanisms, called the **reset gate** and the **update gate**.\n",
    "\n",
    "The reset gate determines how much of the previous hidden state should be forgotten, while the update gate determines how much of the new input should be used to update the hidden state. The output of the GRU is calculated based on the updated hidden state.\n",
    "\n",
    "To solve the *Vanishing-Exploding* gradients problem often encountered during the operation of a basic Recurrent Neural Network, many variations were developed. One of the most famous variations is the *Long Short Term Memory Network(LSTM)*. One of the lesser-known but equally effective variations is the *Gated Recurrent Unit Network(GRU)*. \n",
    "\n",
    "Unlike LSTM, it consists of only three gates and does not maintain an Internal Cell State. The information which is stored in the Internal Cell State in an LSTM\n",
    "\n",
    "from (https://www.geeksforgeeks.org/gated-recurrent-unit-networks/#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CustomizedAdvancedModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 85, 128)           640000    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 85, 128)          0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 128)               99072     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 739,201\n",
      "Trainable params: 739,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/5\n",
      "18750/18750 [==============================] - ETA: 0s - loss: 0.9955 - accuracy: 0.7537 - auc: 0.8362\n",
      "Epoch 1: val_accuracy improved from -inf to 0.68750, saving model to best_model1.h5\n",
      "18750/18750 [==============================] - 2590s 137ms/step - loss: 0.9955 - accuracy: 0.7537 - auc: 0.8362 - val_loss: 0.6118 - val_accuracy: 0.6875 - val_auc: 0.7515\n",
      "Epoch 2/5\n",
      "18750/18750 [==============================] - ETA: 0s - loss: 0.9615 - accuracy: 0.7648 - auc: 0.8487\n",
      "Epoch 2: val_accuracy did not improve from 0.68750\n",
      "18750/18750 [==============================] - 2131s 114ms/step - loss: 0.9615 - accuracy: 0.7648 - auc: 0.8487 - val_loss: 0.6071 - val_accuracy: 0.6719 - val_auc: 0.7672\n",
      "Epoch 3/5\n",
      "18750/18750 [==============================] - ETA: 0s - loss: 0.9451 - accuracy: 0.7701 - auc: 0.8545\n",
      "Epoch 3: val_accuracy improved from 0.68750 to 0.70312, saving model to best_model1.h5\n",
      "18750/18750 [==============================] - 30143s 2s/step - loss: 0.9451 - accuracy: 0.7701 - auc: 0.8545 - val_loss: 0.5898 - val_accuracy: 0.7031 - val_auc: 0.7672\n",
      "Epoch 4/5\n",
      "18750/18750 [==============================] - ETA: 0s - loss: 0.9327 - accuracy: 0.7740 - auc: 0.8588\n",
      "Epoch 4: val_accuracy did not improve from 0.70312\n",
      "18750/18750 [==============================] - 1837s 98ms/step - loss: 0.9327 - accuracy: 0.7740 - auc: 0.8588 - val_loss: 0.5868 - val_accuracy: 0.6719 - val_auc: 0.7676\n",
      "Epoch 5/5\n",
      "18750/18750 [==============================] - ETA: 0s - loss: 0.9260 - accuracy: 0.7763 - auc: 0.8611\n",
      "Epoch 5: val_accuracy did not improve from 0.70312\n",
      "18750/18750 [==============================] - 2797s 149ms/step - loss: 0.9260 - accuracy: 0.7763 - auc: 0.8611 - val_loss: 0.6212 - val_accuracy: 0.6875 - val_auc: 0.7652\n",
      "\n",
      "GRU model Score : [0.48528698086738586, 0.7648674845695496, 0.8482881188392639]\n",
      "Training the model took : 39812.01535606384 seconds \n"
     ]
    }
   ],
   "source": [
    "# 9. Setup the RNN model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GRU, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Keeping a fixed length of all tweets to max 160 words\n",
    "max_words = Xtrain_.shape[1]\n",
    "\n",
    "# fixing every word's embedding size to be 32\n",
    "embd_len = 128\n",
    "\n",
    "# loss function\n",
    "loss = 'binary_crossentropy'\n",
    "\n",
    "# optimizer, using Adam due to robustness\n",
    "adam = Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "gru_model = Sequential(name='CustomizedAdvancedModel')\n",
    "\n",
    "# Add embedding layer\n",
    "gru_model.add(Embedding(vocab_size,\n",
    "                    embd_len,\n",
    "                    input_length=max_words))\n",
    "\n",
    "# add dropout layer\n",
    "gru_model.add(SpatialDropout1D(0.3))\n",
    "\n",
    "# add the GRU layer\n",
    "gru_model.add(GRU(128,\n",
    "              activation='tanh',\n",
    "              return_sequences=False))\n",
    "\n",
    "# add the output layer\n",
    "gru_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# print model summary\n",
    "print(gru_model.summary())\n",
    "\n",
    "# Model Hyperparameters\n",
    "gru_model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=adam,\n",
    "    metrics=['accuracy', AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Get weights\n",
    "frequencies = pd.value_counts(ytrain)\n",
    "weights = {0: frequencies.sum() / frequencies[0], 1: frequencies.sum() / frequencies[1]}\n",
    "\n",
    "# Save the best model\n",
    "cp = ModelCheckpoint(\"best_model1.h5\",\n",
    "                     monitor='val_accuracy',\n",
    "                     verbose=1,\n",
    "                     save_best_only=True,\n",
    "                     mode='auto',\n",
    "                     period=1,\n",
    "                     save_weights_only=False)\n",
    "\n",
    "# Train the GRU model\n",
    "gru_model.fit(Xtrain_, ytrain,\n",
    "          batch_size=64,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, yvalid),\n",
    "          callbacks = [cp],\n",
    "          class_weight = weights)\n",
    "\n",
    "# Print model score on test data\n",
    "print()\n",
    "print(f'GRU model Score : {gru_model.evaluate(Xtest_, ytest, verbose =0)}')\n",
    "print(\"Training the model took : %s seconds \" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU model Score : [0.39110904932022095, 0.8224725127220154, 0.9047358632087708]\n"
     ]
    }
   ],
   "source": [
    "print(f'GRU model Score : {gru_model.evaluate(Xtest_, ytest, verbose =0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model took : 9273.00593161583 seconds \n"
     ]
    }
   ],
   "source": [
    "print(\"Training the model took : %s seconds \" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10a. Function to predict and evaluate model\n",
    "def pred_test(model,x_test, y_test):\n",
    "    from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, classification_report, confusion_matrix\n",
    "    # generate predictions (probabilities)\n",
    "    y_pred_ = model.predict(x_test)\n",
    "\n",
    "    # predictions\n",
    "    y_pred = (model.predict(x_test) > 0.5).astype(int)\n",
    "\n",
    "    # Generate a confusion matrix for the model\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_df = pd.DataFrame(\n",
    "        cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    "        )\n",
    "\n",
    "    # Print the classification report for the model\n",
    "    print(\"Confusion Matrix\")\n",
    "    display(cm_df)\n",
    "\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Accuracy Score : {accuracy_score(y_test, y_pred): .3f}, \\\n",
    "        Recall score: {recall_score(y_test, y_pred): .3f}\")\n",
    "    print(f'Area Under Curve: {roc_auc_score(y_test, y_pred_): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 206s 16ms/step\n",
      "12500/12500 [==============================] - 184s 15ms/step\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>164858</td>\n",
       "      <td>34723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>36484</td>\n",
       "      <td>163935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0       164858        34723\n",
       "Actual 1        36484       163935"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82    199581\n",
      "           1       0.83      0.82      0.82    200419\n",
      "\n",
      "    accuracy                           0.82    400000\n",
      "   macro avg       0.82      0.82      0.82    400000\n",
      "weighted avg       0.82      0.82      0.82    400000\n",
      "\n",
      "Accuracy Score :  0.822,         Recall score:  0.818\n",
      "Area Under Curve:  0.9047\n"
     ]
    }
   ],
   "source": [
    "# 10b. Make predictions and evaluate model\n",
    "# load the best model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model = load_model('best_model.h5')\n",
    "pred_test(best_model, Xtest_, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Positive predicted positive: 0.8288585413558595\n",
      "Negative predicted negative: 0.8160596449561832\n"
     ]
    }
   ],
   "source": [
    "print(f' Positive predicted positive: {166119/200419}\\nNegative predicted negative: {162870/199581}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 349s 28ms/step\n",
      "12500/12500 [==============================] - 357s 29ms/step\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>147686</td>\n",
       "      <td>51895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>41482</td>\n",
       "      <td>158937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0       147686        51895\n",
       "Actual 1        41482       158937"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76    199581\n",
      "           1       0.75      0.79      0.77    200419\n",
      "\n",
      "    accuracy                           0.77    400000\n",
      "   macro avg       0.77      0.77      0.77    400000\n",
      "weighted avg       0.77      0.77      0.77    400000\n",
      "\n",
      "Accuracy Score :  0.767,         Recall score:  0.793\n",
      "Area Under Curve:  0.8503\n"
     ]
    }
   ],
   "source": [
    "# 10b. Make predictions and evaluate model\n",
    "# load the best model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model = load_model('best_model1.h5')\n",
    "pred_test(best_model, Xtest_, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11a. Function to make predictions\n",
    "\n",
    "def predict_sentiment(model, tweet):\n",
    "    # sentiment = ['Negative','Positive']\n",
    "    max_len = 85 #40\n",
    "    sequence = tokenizer.texts_to_sequences([tweet])\n",
    "    text = pad_sequences(sequence, maxlen=max_len)\n",
    "    # sent = sentiment[np.around(model.predict(text), decimals=0).argmax(axis=1)[0]]\n",
    "    prediction = (model.predict(text) > 0.5).astype(int)\n",
    "    return 'Positive' if prediction == 1 else 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "The food and service was a   and this data science article is the good human subject service superb airplane africa. The predicted sentiment is [Positive]\n"
     ]
    }
   ],
   "source": [
    "# 11b. Supply Tweet and apply model to classify\n",
    "model = load_model('best_model1.h5')\n",
    "message = 'The food and service was a   and this data science article is the good human subject service superb airplane africa'\n",
    "max_words = 85 \n",
    "print(f'{message}. The predicted sentiment is [{predict_sentiment(model, message)}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis APP\n",
    "Sentiment analysis, also known as opinion mining involves the use of computational methods to determine the sentiment or emotional tone expressed in a piece of text, such as positive, negative, or neutral. \n",
    "Sentiment Analysis is a natural language processing (often referred to as NLP) and machine learning to interpret and classify emotions in text information.\n",
    "Sentiment analysis plays a crucial role in various industries as companies can use this analysis to improve user experience, product quality, brand reputation and generally the going concern of a business.\n",
    "\n",
    "For this project, the core functionality is to predect the sentiment of a tet, review or document.\n",
    "\n",
    "Sentiment prediction can be outlined as a process that follows the below steps/methods:\n",
    "* Data/Input (Text): User can enter texts/sentences in the regular language format in the provided text area of the application.\n",
    "* Language Detection: Before performing any analysis, we need to determine the language of the input text. (Process can be automated through use the Langdetect library). It detects the language of each text input and enables language-specific sentiment analysis.\n",
    "* Sentiment Analysis: Once the language of the text is determined, we can proceed with sentiment analysis using the SentimentIntensityAnalyzer. The analyzer calculates sentiment scores for each text, including a compound score that represents the overall sentiment. Positive scores indicate positive sentiment, negative scores indicate negative sentiment, and scores around zero indicate neutrality.\n",
    "* Thresholds and Sentiment Categorization: To categorize the sentiment, we define threshold values for positive and negative sentiments. The user can adjust these thresholds using the number inputs in the application. Sentiment scores above the positive threshold are considered positive, scores below the negative threshold are considered negative, and scores in between are classified as neutral.\n",
    "* Sentiment Labels and Confidence Scores: Based on the sentiment scores and the defined thresholds, the sentiment of each text is determined as positive, negative, or neutral. Additionally, we calculate a confidence score, which represents the intensity of the sentiment. The confidence score is derived from the compound score and is expressed as a percentage.\n",
    "* Tabular Representation: The sentiment predictions, along with the original texts and confidence scores, are organized into a DataFrame using the Pandas library. This tabular representation provides a clear overview of the sentiment analysis results.\n",
    "* Visualization: To enhance the understanding of sentiment distribution, we create a pie chart using the Matplotlib library. The pie chart illustrates the proportion of positive, negative, and neutral sentiments in the analyzed texts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
